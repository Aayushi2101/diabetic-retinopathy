import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam

# ----------- Configuration -----------
IMG_SIZE = 224
NUM_CLASSES = 5
DATA_DIR = r"C:\Users\tembh\OneDrive\Desktop\python\dataset\diabetes"

# ----------- Optional: CLAHE preprocessing -----------
def preprocess_image(img):
    green_channel = img[:, :, 1]
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    green_eq = clahe.apply(green_channel)
    return cv2.merge([green_eq, green_eq, green_eq])

# ----------- Load and Preprocess Data -----------
def load_data(data_dir):
    X, y = [], []
    for label in range(NUM_CLASSES):
        folder_path = os.path.join(data_dir, str(label))
        if not os.path.exists(folder_path):
            print(f"[WARNING] Folder not found: {folder_path}")
            continue
        for file in os.listdir(folder_path):
            img_path = os.path.join(folder_path, file)
            img = cv2.imread(img_path)
            if img is not None:
                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
                img = preprocess_image(img)  # comment this line to disable CLAHE
                X.append(img)
                y.append(label)
    return np.array(X), np.array(y)

print("[INFO] Loading and preprocessing data...")
X, y = load_data(DATA_DIR)

if len(X) == 0:
    raise Exception("No images found! Check your dataset path.")

X = X.astype("float32") / 255.0
y_cat = to_categorical(y, NUM_CLASSES)

# ----------- Train/Test Split -----------
X_train, X_test, y_train_cat, y_test_cat = train_test_split(X, y_cat, test_size=0.2, stratify=y, random_state=42)

# Convert categorical back to labels for confusion matrix
y_test_labels = np.argmax(y_test_cat, axis=1)

# ----------- Data Augmentation -----------
datagen = ImageDataGenerator(
    rotation_range=20,
    zoom_range=0.15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)
datagen.fit(X_train)

# ----------- Build DenseNet Model -----------
base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
for layer in base_model.layers:
    layer.trainable = False  # Freeze base model

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
output = Dense(NUM_CLASSES, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)
model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

# ----------- Train the Model -----------
print("[INFO] Training the model...")
history = model.fit(
    datagen.flow(X_train, y_train_cat, batch_size=32),
    validation_data=(X_test, y_test_cat),
    epochs=10
)

# ----------- Plot Accuracy and Loss -----------
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

# ----------- Evaluate and Confusion Matrix -----------
print("[INFO] Evaluating model...")
y_pred_probs = model.predict(X_test)
y_pred_labels = np.argmax(y_pred_probs, axis=1)

print("\nClassification Report:")
print(classification_report(y_test_labels, y_pred_labels))

conf_matrix = confusion_matrix(y_test_labels, y_pred_labels)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=[f'Class {i}' for i in range(NUM_CLASSES)],
            yticklabels=[f'Class {i}' for i in range(NUM_CLASSES)])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.tight_layout()
plt.show()

# ----------- Save Model -----------
model.save("densenet_dr_model_fixed.h5")
print("[INFO] Model saved as densenet_dr_model_fixed.h5")

